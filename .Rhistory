View(mycorpus)
mycorpus$V1
typeof(mycorpus$V1)
typeof(toString(mycorpus$V1))
toString(mycorpus$V1)
cat("lala", "ladida")
cat("lalaladida")
cat("lal","aladida")
mycorpus <- cat(toString(mycorpus$V1), toString(mycorpus$V2), toString(mycorpus$V3), toString(mycorpus$V4), toString(mycorpus$V5), toString(mycorpus$V6), toString(mycorpus$V7), toString(mycorpus$V8), toString(mycorpus$V9), toString(mycorpus$V10), toString(mycorpus$V11), toString(mycorpus$V12), toString(mycorpus$V13), toString(mycorpus$V14))
mycorpus <- removePunctuation(mycorpus)
typeof(mycorpus)
removePunctuation(toString(mycorpus$V1))
mycorpus <- as.String(read.table("namyths.txt", fill = TRUE))
mycorpus
filename <- "namyths.txt"
mycorpus <- readChar(fileName, file.info(fileName)$size)
fileName <- "namyths.txt"
mycorpus <- readChar(fileName, file.info(fileName)$size)
mycorpus
mycorpus <- removePunctuation(mycorpus)
mycorpus
mycorpus <- tolower(mycorpus)
mycorpus <- stemDocument(mycorpus)
mycorpus <- removeWords(corpus, stopwords())
mycorpus
for(j in 1:length(mycorpus)){
text <- corpus[[j]]$content
text <- strsplit(text, split=' ')
text <- text[[1]]
for(i in 1:length(text)) {
word1 <- text[i]
word2 <- text[i+1]
occurances[[word1]] <- c(occurances[[word1]], word2)
}
}
occurances
occurances <- list()
for(j in 1:length(mycorpus)){
text <- corpus[[j]]$content
text <- strsplit(text, split=' ')
text <- text[[1]]
for(i in 1:length(text)) {
word1 <- text[i]
word2 <- text[i+1]
occurances[[word1]] <- c(occurances[[word1]], word2)
}
}
occurances
names(occurances)
text <- mycorpusÄ‘
text <- mycorpus
text <- strsplit(text, split=' ')
text <- text[[1]]
for(i in 1:length(text)) {
word1 <- text[i]
word2 <- text[i+1]
occurances[[word1]] <- c(occurances[[word1]], word2)
}
names(occurances)
sorted_table <- sort(table(occurances[["time"]]), decreasing=T)
sorted_table
sorted_table[1]
stopWords <- stopwords("en")
mycorpus <- unlist(mycorpus)[!(unlist(mycorpus) %in% stopWords)]
mycorpus
mycorpus <- removeWords(mycorpus, stopWords)
mycorpus
text <- strsplit(text, split = ' ')
text <- text[[1]]
text <- mycorpus
text <- strsplit(text, split=' ')
text <- text[[1]]
for(i in 1:length(text)) {
word1 <- text[i]
word2 <- text[i+1]
occurances[[word1]] <- c(occurances[[word1]], word2)
}
names(occurances)
occurances[["time"]]
table <- table(occurances[["time"]])
table
sorted_table <- sort(table(occurances[["time"]]), decreasing=T)
sorted_table
names(sorted_table[1])
names(sorted_table[2])
text
fileName <- "namyths.txt"
mycorpus <- readChar(fileName, file.info(fileName)$size)
mycorpus <- removePunctuation(mycorpus)
mycorpus <- tolower(mycorpus)
mycorpus <- removeWords(mycorpus, stopWords)
mycorpus <- stemDocument(mycorpus)
occurances <- list()
mycorpus
fileName <- "namyths.txt"
mycorpus <- readChar(fileName, file.info(fileName)$size)
mycorpus <- removePunctuation(mycorpus)
remove(list = ls())
fileName <- "namyths.txt"
mycorpus <- readChar(fileName, file.info(fileName)$size)
mycorpus <- removePunctuation(mycorpus)
mycorpus <- removeNumbers(mycorpus)
mycorpus <- tolower(mycorpus)
mycorpus <- removeWords(mycorpus, stopWords)
stopWords <- stopwords("en")
mycorpus <- removeWords(mycorpus, stopWords)
mycorpus <- stemDocument(mycorpus)
occurances <- list()
mycorpus
text <- mycorpus
text <- strsplit(text, split=' ')
text <- text[[1]]
for(i in 1:length(text)) {
word1 <- text[i]
word2 <- text[i+1]
occurances[[word1]] <- c(occurances[[word1]], word2)
}
names(occurances)
occurances[["project"]]
sorted_table <- sort(table(occurances[["project"]]), decreasing=T)
names(sorted_table[1])
sent <- "Today I will work on project"
lookfor <- strsplit(sent, split=' ')
lookfor
lookfor <- lookfor[[1]]
lookfor
lookfor[length(lookfor)]
finish_sent <- function(sent, mycorpus) {
text <- mycorpus
text <- strsplit(text, split=' ')
text <- text[[1]]
lookfor <- strsplit(sent, split=' ')
lookfor <- lookfor[[1]]
lookfor <- lookfor[length(lookfor)]
occurances <- list()
for(i in 1:length(text)) {
word1 <- text[i]
word2 <- text[i+1]
occurances[[word1]] <- c(occurances[[word1]], word2)
}
sorted_table <- sort(table(occurances[[lookfor]]), decreasing=T)
predict <- names(sorted_table[1])
return(cat(sent, predict, "."))
}
sent
typeof(mycorpus)
finish_sent(sent, mycorpus)
finish_sent("I dont have time", mycorpus)
finish_sent("I dont have time to ", mycorpus)
finish_sent("The past", mycorpus)
finish_sent <- function(sent, mycorpus) {
text <- mycorpus
text <- strsplit(text, split=' ')
text <- text[[1]]
lookfor <- strsplit(sent, split=' ')
lookfor <- lookfor[[1]]
lookfor <- lookfor[length(lookfor)]
occurances <- list()
for(i in 1:length(text)) {
word1 <- text[i]
word2 <- text[i+1]
word3 <- text[i+2]
occurances[[word1]] <- c(occurances[[word1]], word2, word3)
}
sorted_table <- sort(table(occurances[[lookfor]]), decreasing=T)
predict <- names(sorted_table[1])
return(cat(sent, predict, "."))
}
finish_sent(sent, mycorpus)
finish_sent <- function(sent, mycorpus) {
text <- mycorpus
text <- strsplit(text, split=' ')
text <- text[[1]]
lookfor <- strsplit(sent, split=' ')
lookfor <- lookfor[[1]]
lookfor <- lookfor[length(lookfor)]
occurances <- list()
for(i in 2:length(text)) {
word0 <- text[i - 1]
word1 <- text[i]
word2 <- text[i + 1]
word3 <- text[i + 2]
occurances[[word1]] <- c(word0, occurances[[word1]], word2, word3)
}
sorted_table <- sort(table(occurances[[lookfor]]), decreasing=T)
predict <- names(sorted_table[1])
return(cat(sent, predict, "."))
}
finish_sent(sent, mycorpus)
finish_sent(sent0, mycorpus)
sent0 <- "Today I will work on project"
sent1 <- "I dont have time"
sent2 <- "In the past"
sent3 <- "The future"
finish_sent(sent0, mycorpus)
finish_sent(sent1, mycorpus)
finish_sent <- function(sent, mycorpus) {
text <- mycorpus
text <- strsplit(text, split=' ')
text <- text[[1]]
lookfor <- strsplit(sent, split=' ')
lookfor <- lookfor[[1]]
lookfor <- lookfor[length(lookfor)]
occurances <- list()
for(i in 2:length(text)) {
word0 <- text[i - 1]
word1 <- text[i]
word2 <- text[i + 1]
word3 <- text[i + 2]
occurances[[word1]] <- c(occurances[[word1]], word2, word3)
}
sorted_table <- sort(table(occurances[[lookfor]]), decreasing=T)
predict <- names(sorted_table[1])
return(cat(sent, predict, "."))
}
finish_sent(sent0, mycorpus)
finish_sent(sent1, mycorpus)
finish_sent(sent2, mycorpus)
finish_sent(sent3, mycorpus)
mycorpus
sent
charcount(mycorpus)
nchar(mycorpus)
sent
gsub("project", "proj", sent)
finish_sent <- function(sent, mycorpus, mode) {
text <- mycorpus
text <- strsplit(text, split=' ')
text <- text[[1]]
lookfor <- strsplit(sent, split=' ')
lookfor <- lookfor[[1]]
lookfor <- lookfor[length(lookfor)]
occurances <- list()
for(i in 2:length(text)) {
word0 <- text[i - 1]
word1 <- text[i]
word2 <- text[i + 1]
word3 <- text[i + 2]
if(mode == "back") {
occurances[[word1]] <- c(word0, occurances[[word1]], word2, word3)
}
else {
occurances[[word1]] <- c(occurances[[word1]], word2, word3)
}
}
if(mode == "back") {
sorted_table <- sort(table(occurances[[lookfor]]), decreasing=T)
predict <- names(sorted_table[1])
tmp_sent <- gsub(lookfor, predicted, sent)
return(cat(tmp_sent, lookfor, "."))
}
sorted_table <- sort(table(occurances[[lookfor]]), decreasing=T)
predict <- names(sorted_table[1])
return(cat(sent, predict, "."))
}
finish_sent(sent1, mycorpus)
finish_sent(sent1, mycorpus, "back")
finish_sent <- function(sent, mycorpus, mode) {
text <- mycorpus
text <- strsplit(text, split=' ')
text <- text[[1]]
lookfor <- strsplit(sent, split=' ')
lookfor <- lookfor[[1]]
lookfor <- lookfor[length(lookfor)]
occurances <- list()
for(i in 2:length(text)) {
word0 <- text[i - 1]
word1 <- text[i]
word2 <- text[i + 1]
word3 <- text[i + 2]
if(mode == "back") {
occurances[[word1]] <- c(word0, occurances[[word1]], word2, word3)
}
else {
occurances[[word1]] <- c(occurances[[word1]], word2, word3)
}
}
if(mode == "back") {
sorted_table <- sort(table(occurances[[lookfor]]), decreasing=T)
predict <- names(sorted_table[1])
tmp_sent <- gsub(lookfor, predict, sent)
return(cat(tmp_sent, lookfor, "."))
}
sorted_table <- sort(table(occurances[[lookfor]]), decreasing=T)
predict <- names(sorted_table[1])
return(cat(sent, predict, "."))
}
finish_sent(sent1, mycorpus, "back")
finish_sent(sent1, mycorpus, "normal")
finish_sent(sent0, mycorpus, "back")
remove(list = ls())
setwd("D:/FRI/3.letnik/IS/")
source <- DirSource("essay")
source$filelist <- mixedsort(source$filelist)
corpus <- Corpus(source)
library(gtools)
setwd("D:/FRI/3.letnik/IS/")
source <- DirSource("essay")
source$filelist <- mixedsort(source$filelist)
corpus <- Corpus(source)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removeWords, stopwords())
corpus <- tm_map(corpus, stemDocument)
sent_ann <- Maxent_Sent_Token_Annotator()
word_ann <- Maxent_Word_Token_Annotator()
avg_sent_len <- function(text, sent_ann, word_ann) {
# Count the sentences
a1 <- annotate(text, sent_ann)
num_sents <- length(a1)
# Count the words
a2 <- annotate(text, word_ann, a1)
# a2 also contains the sentence annotation, so we subtract them to obtain the
# correct number of words
num_words <- length(a2) - length(a1)
return(num_words/num_sents)
}
doc_sent_num <- function(text, sent_ann) {
# Count the sentences
a1 <- annotate(text, sent_ann)
num_sents <- length(a1)
return(num_sents)
}
doc_word_num <- function(text, sent_ann, word_ann) {
a1 <- annotate(text, sent_ann)
num_sents <- length(a1)
a2 <- annotate(text, word_ann, a1)
num_words <- length(a2) - length(a1)
return(num_words)
}
doc_rare_word <- function(dataset) {
rare_list <- c()
for (i in c(1:723)) {
rare_list <- c(rare_list, length(which(dataset[i,]$v < 0.002, arr.ind = T)))
}
return(rare_list)
}
sent_lens <- lapply(corpus, avg_sent_len, sent_ann, word_ann)
doc_words <- lapply(corpus, doc_word_num, sent_ann, word_ann)
doc_sents <- lapply(corpus, doc_sent_num, sent_ann)
rare_list <- doc_rare_word(dataset)
corpus <- tm_map(corpus, removePunctuation)
dataset <- DocumentTermMatrix(corpus, control = list(weighting = weightTfIdf))
popular_words <- unlist(findMostFreqTerms(dataset,n=1));
rare_list <- doc_rare_word(dataset)
plot(x = c(1:723), y=rare_list, type="h", main = "x=document_id y=word_num_len")
plot(x = c(1:723), y=rare_list, type="h", main = "x=document_id y=rare_words_num")
plot(x = c(1:723), y=sent_lens, type="h", main = "x=document_id y=avg_sen_len")
plot(x = c(1:723), y=doc_sents, type="h", main = "x=document_id y=sen_len")
plot(x = c(1:723), y=doc_words, type="h", main = "x=document_id y=word_num_len")
popular_words
mycorpus
remove(ls())
remove(list = ls())
stopWords <- stopwords("en")
fileName <- "namyths.txt"
mycorpus <- readChar(fileName, file.info(fileName)$size)
mycorpus <- removePunctuation(mycorpus)
mycorpus <- removeNumbers(mycorpus)
mycorpus <- tolower(mycorpus)
mycorpus <- removeWords(mycorpus, stopWords)
mycorpus <- stemDocument(mycorpus)
sent0 <- "Today I will work on project"
sent1 <- "I dont have time"
sent2 <- "In the past"
sent3 <- "The future"
finish_sent <- function(sent, mycorpus, mode) {
text <- mycorpus
text <- strsplit(text, split=' ')
text <- text[[1]]
lookfor <- strsplit(sent, split=' ')
lookfor <- lookfor[[1]]
lookfor <- lookfor[length(lookfor)]
occurances <- list()
for(i in 2:length(text)) {
word0 <- text[i - 1]
word1 <- text[i]
word2 <- text[i + 1]
word3 <- text[i + 2]
if(mode == "back") {
occurances[[word1]] <- c(word0, occurances[[word1]], word2, word3)
}
else {
occurances[[word1]] <- c(occurances[[word1]], word2, word3)
}
}
if(mode == "back") {
sorted_table <- sort(table(occurances[[lookfor]]), decreasing=T)
predict <- names(sorted_table[1])
tmp_sent <- gsub(lookfor, predict, sent)
return(cat(tmp_sent, lookfor, "."))
}
sorted_table <- sort(table(occurances[[lookfor]]), decreasing=T)
predict <- names(sorted_table[1])
return(cat(sent, predict, "."))
}
mycorpus
sent1 <- "I don't have time"
1:5
finish_sent(sent0, mycorpus, "normal")
stopWords <- stopwords("en")
fileName <- "namyths.txt"
mycorpus <- readChar(fileName, file.info(fileName)$size)
mycorpus <- removePunctuation(mycorpus)
mycorpus <- removeNumbers(mycorpus)
mycorpus <- tolower(mycorpus)
mycorpus <- removeWords(mycorpus, stopWords)
finish_sent(sent0, mycorpus, "normal")
mycorpus <- stemDocument(mycorpus)
finish_sent(sent1, mycorpus, "normal")
finish_sent(sent0, mycorpus, "normal")
finish_sent(sent1, mycorpus, "back")
finish_sent <- function(sent, mycorpus, mode) {
text <- mycorpus
text <- strsplit(text, split=' ')
text <- text[[1]]
lookfor <- strsplit(sent, split=' ')
lookfor <- lookfor[[1]]
lookfor <- lookfor[length(lookfor)]
occurances <- list()
for(i in 2:length(text)) {
word0 <- text[i - 1]
word1 <- text[i]
word2 <- text[i + 1]
word3 <- text[i + 2]
if(mode == "back") {
occurances[[word1]] <- c(word0, occurances[[word1]])
}
else {
occurances[[word1]] <- c(occurances[[word1]], word2, word3)
}
}
if(mode == "back") {
sorted_table <- sort(table(occurances[[lookfor]]), decreasing=T)
predict <- names(sorted_table[1])
tmp_sent <- gsub(lookfor, predict, sent)
return(cat(tmp_sent, lookfor, "."))
}
sorted_table <- sort(table(occurances[[lookfor]]), decreasing=T)
predict <- names(sorted_table[1])
return(cat(sent, predict, "."))
}
finish_sent(sent1, mycorpus, "back")
popular_words <- unlist(findMostFreqTerms(dataset,n=1));
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removeWords, stopwords())
corpus <- tm_map(corpus, stemDocument)
setwd("D:/FRI/3.letnik/IS/")
source <- DirSource("essay")
source$filelist <- mixedsort(source$filelist)
corpus <- Corpus(source)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removeWords, stopwords())
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removePunctuation)
dataset <- DocumentTermMatrix(corpus, control = list(weighting = weightTfIdf))
popular_words <- unlist(findMostFreqTerms(dataset,n=1));
popular_words
install.packages("wordcloud")
library(wordcloud)
coud_mtx <- as.matrix(dataset)
v <- sort(rowSums(coud_mtx),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
coud_mtx <- as.matrix(popular_words)
v <- sort(rowSums(coud_mtx),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
coud_mtx <- as.matrix(names(popular_words))
v <- sort(rowSums(coud_mtx),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
coud_mtx <- as.matrix(names(dataset))
v <- sort(rowSums(coud_mtx),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
coud_mtx <- as.matrix(names(dataset))
v <- sort(rowSums(coud_mtx),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
coud_mtx <- as.matrix(dataset)
v <- sort(rowSums(coud_mtx),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
View(dataset)
coud_mtx <- as.matrix(dataset$dimnames$Terms)
v <- sort(rowSums(coud_mtx),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
